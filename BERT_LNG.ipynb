{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "df = pd.read_excel(r\"file_path\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# 한국어 BERT 모델과 토크나이저 로드\n",
    "bert_model_name = \"kykim/bert-kor-base\"\n",
    "bert_model = BertForMaskedLM.from_pretrained(bert_model_name)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "\n",
    "# 감성 분석 함수 정의\n",
    "def predict_stock_sentiment_bert_korean(headline):\n",
    "    # 문장 구조를 한국어에 맞게 변경\n",
    "    sentence = f\"{headline}는 LNG 가격에 [MASK] 영향을 줄 것이다.\"\n",
    "    input_ids = bert_tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "    mask_pos = input_ids[0].tolist().index(bert_tokenizer.mask_token_id)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = bert_model(torch.tensor(input_ids))[0]\n",
    "        predicted_token_id = torch.argmax(logits[0, mask_pos]).item()\n",
    "        predicted_word = bert_tokenizer.decode(predicted_token_id)\n",
    "    \n",
    "    print(predicted_word)\n",
    "    predicted_word = predicted_word.replace(\" \", \"\")\n",
    "    print(predicted_word)\n",
    "\n",
    "    # 긍정/부정 단어 감정 분석 (한국어의 경우에는 '긍정적', '부정적'과 같은 단어를 기준으로 할 수 있습니다.)\n",
    "    if predicted_word == '긍정적인':\n",
    "        return 1\n",
    "    elif predicted_word == '부정적인':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "# 뉴스 헤드라인 예시 (한국어 예시로 변경)\n",
    "headline_korean = \"News_HeadLine\"\n",
    "sentiment_bert_korean = predict_stock_sentiment_bert_korean(headline_korean)\n",
    "\n",
    "# 결과 출력\n",
    "headline_korean, sentiment_bert_korean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each headline\n",
    "df[\"sentiment_bert_korean\"] = df[\"News\"].apply(predict_stock_sentiment_bert_korean)\n",
    "# Extract the month from the date\n",
    "df['Month'] = df['Date'].dt.to_period('M')\n",
    "# Group by month and calculate the sum of ChatGPT scores for each month\n",
    "monthly_scores = df.groupby('Month')[\"sentiment_bert_korean\"].sum().reset_index()\n",
    "\n",
    "print(monthly_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_scores.to_excel('monthly_scores.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
